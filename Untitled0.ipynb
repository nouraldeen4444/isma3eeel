{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nouraldeen4444/isma3eeel/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "bzpuNltGWeD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import elm\n",
        "from elm import ELMKernel\n",
        "from keras.engine.training import Model\n",
        "import keras\n",
        "#from keras.optimizer_v2 import learning_rate_schedule\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Flatten, Dropout, Conv1D, GlobalMaxPooling1D, Dense ,Concatenate ,Input\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import torch\n",
        "import xmltodict\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "#--------------------------------------------------------------------------------------\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "from google.colab import files\n",
        "from keras import backend as K\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "rMHLStyLwgMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG25XTqyWN01",
        "outputId": "72eb9714-b9f0-4368-f36e-0c1d113c378f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['with_mask', 'mask_weared_incorrect', 'without_mask']) \n",
            " dict_values([3232, 123, 717])\n"
          ]
        }
      ],
      "source": [
        "img_names=[] \n",
        "xml_names=[] \n",
        "for dirname, _, filenames in os.walk('train'):\n",
        "    for filename in filenames:\n",
        "        if os.path.join(dirname, filename)[-3:]!=\"xml\":\n",
        "            img_names.append(filename)\n",
        "        else:\n",
        "            xml_names.append(filename)\n",
        "path_annotations=\"train/annotations/\" \n",
        "listing=[]\n",
        "for i in img_names[:]:\n",
        "    with open(path_annotations+i[:-4]+\".xml\") as fd:\n",
        "        doc=xmltodict.parse(fd.read())\n",
        "    temp=doc[\"annotation\"][\"object\"]\n",
        "    if type(temp)==list:\n",
        "        for i in range(len(temp)):\n",
        "            listing.append(temp[i][\"name\"])\n",
        "    else:\n",
        "        listing.append(temp[\"name\"])\n",
        "        \n",
        "\n",
        "Items = Counter(listing).keys()\n",
        "values = Counter(listing).values()\n",
        "print(Items,'\\n',values)     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.functional import norm\n",
        "options={\"with_mask\":0,\"without_mask\":1,\"mask_weared_incorrect\":2} \n",
        "def dataset_creation(image_list): \n",
        "    image_tensor=[]\n",
        "    label_tensor=[]\n",
        "    for i,j in enumerate(image_list):\n",
        "        with open(path_annotations+j[:-4]+\".xml\") as fd:\n",
        "            doc=xmltodict.parse(fd.read())\n",
        "        if type(doc[\"annotation\"][\"object\"])!=list:\n",
        "            temp=doc[\"annotation\"][\"object\"]\n",
        "            x,y,w,h=list(map(int,temp[\"bndbox\"].values()))\n",
        "            label=options[temp[\"name\"]]\n",
        "            #image=transforms.functional.crop(Image.open(path_image+j).convert(\"RGB\"), y,x,h-y,w-x)\n",
        "            image=Image.open(path_image+j).convert(\"RGB\")\n",
        "            image_tensor.append(my_transform(image))\n",
        "            label_tensor.append(torch.tensor(label))\n",
        "        else:\n",
        "            temp=doc[\"annotation\"][\"object\"]\n",
        "            for k in range(len(temp)):\n",
        "                x,y,w,h=list(map(int,temp[k][\"bndbox\"].values()))\n",
        "                label=options[temp[k][\"name\"]]\n",
        "                #image=transforms.functional.crop(Image.open(path_image+j).convert(\"RGB\"),y,x,h-y,w-x)\n",
        "                image=Image.open(path_image+j).convert(\"RGB\")\n",
        "                image_tensor.append(my_transform(image))\n",
        "                label_tensor.append(torch.tensor(label))\n",
        "    final_dataset=[[k,l] for k,l in zip(image_tensor,label_tensor)]\n",
        "    return tuple(final_dataset)\n",
        "    my_transform=transforms.Compose([transforms.Resize((226,226)),transforms.ToTensor()])\n"
      ],
      "metadata": {
        "id": "iQnyqBhm_gC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_image=\"/kaggle/input/face-mask-detection/images/\"\n",
        "fun_images = img_names.copy()\n",
        "rows = []\n",
        "for i in range(1, len(fun_images)):\n",
        "    with open(path_annotations+fun_images[i][:-4]+\".xml\") as fd:\n",
        "        doc=xmltodict.parse(fd.read())\n",
        "        temp=doc[\"annotation\"][\"object\"]\n",
        "        for item in temp:    \n",
        "            if (not isinstance(item, str)):\n",
        "                rows.append([fun_images[i], item['name'], int(item['bndbox']['xmin']), int(item['bndbox']['xmax']), int(item['bndbox']['ymin']), int(item['bndbox']['ymax'])])\n",
        "        #annotations.append(rows)\n",
        "annotations_df = pd.DataFrame(np.array(rows), columns =['image', 'label', 'x_min', 'x_max', 'y_min', 'y_max'])  "
      ],
      "metadata": {
        "id": "oBNVMDtwVFEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskDataset(object):\n",
        "    \n",
        "    def __init__(self, root_path, transform=None):\n",
        "        self.root_path = root_path        \n",
        "        self.images_df = annotations_df\n",
        "        self.images_list = annotations_df['image'].unique()\n",
        "        self.labels_dict = {'without_mask': 1, 'with_mask': 2, 'mask_weared_incorrect': 3}\n",
        "        self.transform = transform\n",
        "    \n",
        "    def get(self, idx):\n",
        "        img_path = os.path.join(self.root_path, 'images', self.images_list[idx])\n",
        "        img = np.array(Image.open(img_path).convert('RGB')) / 255\n",
        "        img = np.moveaxis(img, 2, 0) # to [C, H, W]\n",
        "        \n",
        "        if self.transform:\n",
        "            img = np.moveaxis(img, 0, -1)\n",
        "            img = self.transform(image=img)['image']\n",
        "        img_data_df = self.images_df[self.images_df['image'] == self.images_list[idx]]     \n",
        "        n_bboxes = img_data_df.shape[0]\n",
        "        bboxes = []\n",
        "        labels = []\n",
        "        for i in range(n_bboxes):\n",
        "            img_data = img_data_df.iloc[i]\n",
        "            x_min = int(img_data.x_min)\n",
        "            x_max = int(img_data.x_max)\n",
        "            y_min = int(img_data.y_min)\n",
        "            y_max = int(img_data.y_max)\n",
        "            bboxes.append([x_min, y_min, x_max, y_max])\n",
        "            label = self.labels_dict[img_data.label]                \n",
        "            labels.append(label)\n",
        "\n",
        "        # Convert data to tensors\n",
        "        img = torch.as_tensor(img, dtype=torch.float32)    \n",
        "        bboxes = torch.as_tensor(bboxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = bboxes\n",
        "        target['labels'] = labels\n",
        "        target['image_id'] = image_id\n",
        "        return img, target\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        return self.get(idx)\n",
        "        \n",
        "    \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images_list)"
      ],
      "metadata": {
        "id": "eFiKfj5rT8O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "images_df = annotations_df\n",
        "labels_dict = {'without_mask': 0, 'with_mask': 1, 'mask_weared_incorrect': 2}\n",
        "images_list = annotations_df['image'].unique()\n",
        "img_path = os.path.join('train/', 'images', images_list[idx])\n",
        "img = np.array(Image.open(img_path)) / 255\n",
        "\n",
        "img_data_df = images_df[images_df['image'] == images_list[idx]]   \n",
        "for i in range(len(img_data_df)):\n",
        "\n",
        "    img_data = img_data_df.iloc[i]\n",
        "    label = labels_dict[img_data.label]          "
      ],
      "metadata": {
        "id": "IE_6oggAUYWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model(filters = 64, kernel_size = 3, strides=1, units = 256,optimizer='adam', rate = 0.25):\n",
        "  model1 = VGG16(include_top=False,weights='imagenet',input_tensor=None,input_shape=(None,None,3),)\n",
        " # model1.add(Flatten())\n",
        "  model2 = elm.ELMKernel()\n",
        "  print(model1.layers[18].output.get_shape())\n",
        "  get_3rd_layer_output = K.function([model1.layers[0].input],\n",
        "                                  [model1.layers[18].output])\n",
        "  layer_output = get_3rd_layer_output([0])[0]\n",
        " # model2.train(layer_output)\n",
        "#block5_pool \n",
        "#MaxPooling2D\n",
        "#block5_conv3 \n",
        "#Conv2D\n",
        "\n",
        "  # Compile the model\n",
        "  model1.compile(loss='binary_crossentropy',\n",
        "                  optimizer= 'adam',\n",
        "                  metrics=['accuracy'])\n",
        " # elm(hidden_units=32, activation_function='relu', random_type='normal', x=X_train, y=y_train, C=0.1, elm_type='clf')\n",
        "  model1.summary()\n",
        "#  model2.summary()\n",
        "  return model1\n",
        "  # Build the model\n",
        "model1 = KerasClassifier(build_fn= create_model)\n",
        "\n",
        "\n",
        "#filters = [32,128]\n",
        "#kernel_size = [3,5]\n",
        "#strides= [1]\n",
        "#Dense_units = [128,512]\n",
        "#rate_dropouts = [0.25]\n",
        "#optimizers = ['adam']\n",
        "#epochs = [5]\n",
        "#batches = [2,16]\n",
        "# ----------------------------------------------\n",
        "#param_grid = dict(optimizer= optimizers, epochs= epochs,\n",
        " #                 batch_size= batches,filters = filters,\n",
        "  #                kernel_size = kernel_size, strides = strides,\n",
        "   #               units = Dense_units, rate = rate_dropouts)\n",
        "\n",
        "#grid = ParameterGrid(param_grid)\n",
        "#param_sets = list(grid)\n",
        "\n",
        "#param_scores = []\n",
        "#for params in grid:\n",
        " #   print(params)\n",
        "  #  model.set_params(**params)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy',patience=2,verbose=1,factor=0.5,min_lr=0.00001)\n",
        "history = model1.fit(img_data, label,shuffle= True,callbacks =learning_rate_reduction)\n",
        "  #  param_score = history.history['accuracy']\n",
        "   # param_scores.append(param_score[-1])\n",
        "    #print('-'*100) \n",
        "\n",
        "#print('param_scores:', param_scores)\n",
        "#p = np.argmax(np.array(param_scores))\n",
        "#print(\"best score:\", param_scores[p])\n",
        "#best_params = param_sets[p]\n",
        "#print(\"best parameter set\", best_params)\n",
        "#model.set_params(**best_params)\n",
        "#model.fit(np.vstack((X_train, X_val)), np.hstack((y_train, y_val)))\n",
        "#result = model.score(X_test, y_test)\n",
        "#print(\"Test accuracy =\" + str(result*100) +\"%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "fyVENc9sv3AJ",
        "outputId": "d65ec77f-b64e-42f4-f1dd-1fff848cfdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a4be66830dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m#  model.set_params(**params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mlearning_rate_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_reduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;31m#  param_score = history.history['accuracy']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m    \u001b[0;31m# param_scores.append(param_score[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid shape for y: ()"
          ]
        }
      ]
    }
  ]
}